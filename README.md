# Article on Software Engineering

## Link to the Article
[deepseek new AI software became global disruptor](https://www.scientificamerican.com/article/why-deepseeks-ai-model-just-became-the-top-rated-app-in-the-u-s/)

## Why I Find It Interesting

I really enjoyed this article because it shows that even smaller companies can challenge big tech when they’re clever about how they train AI. DeepSeek managed to create a large language model on cheaper, lower-powered hardware—something many people didn’t think was possible—while still matching the performance of much bigger players. Their “mixture of experts” approach is especially cool because it only uses the parts of the model it needs at any given time, which helps keep costs down and makes it less of an environmental strain. Plus, the fact that they’ve open-sourced much of the code means researchers and smaller organizations can actually experiment with this technology without breaking the bank.

## Comment from Jackson Chen
Really insightful analysis! The fact that DeepSeek achieved this with lower-powered hardware shows how innovative architecture design can be just as important as raw computing power.

## Comment from Kevin Jin
DeepSeek-R1’s breakthrough in efficiency and cost-effectiveness challenges the dominance of big-budget AI models, proving that innovation isn’t just about hardware but also smart optimization.
